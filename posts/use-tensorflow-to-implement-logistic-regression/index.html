<!DOCTYPE html>
<html lang="zh">
<head><meta name="generator" content="Hexo 3.8.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    
    <title>使用TensorFlow实现逻辑回归 - 扬涛的博客</title>
    <meta itemprop="name" content="使用TensorFlow实现逻辑回归 - 扬涛的博客">
    <meta name="keywords" content="扬涛的博客, 郑扬涛, orzyt, leetcode">
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <link rel="alternate" href="/atom.xml" title="扬涛的博客" type="application/atom+xml">
    <link rel="icon" href="/favicon.ico">
    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">
    <link rel="stylesheet" href="/libs/bootstrap/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/style.css">
    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    <script src="/libs/bootstrap/js/bootstrap.min.js"></script>
    <script src="/libs/jquery/sort.js"></script>
    




<script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?63f226f2212285cc30d6ffa0636da07a";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->



</head>
</html>
<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">扬涛的博客</span>
            </a>
            <nav id="main-nav">
                <div>
                    <ul class="nav navbar-nav">
                    
                        <a class="main-nav-link" href="/.">主页</a>
                    
                        <a class="main-nav-link" href="/archives">归档</a>
                    
                        <a class="main-nav-link" href="/about">关于</a>
                    
                    
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">
                            更多 
                            <b class="caret"></b>
                        </a>
                        <ul class="dropdown-menu">
                            
                                <li><a href="/study">学习资源汇总</a></li>
                            
                        </ul>
                    </li>
                    
                    </ul>
                </div>
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/img/avatar.png">
                            <i class="fa fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <ul class="menu outer">
            
                <a class="main-nav-link" href="/.">主页</a>
            
                <a class="main-nav-link" href="/archives">归档</a>
            
                <a class="main-nav-link" href="/about">关于</a>
            
                           
            <li class="dropdown">
                <a href="#" class="dropdown-toggle" data-toggle="dropdown">
                    更多 
                    <b class="caret"></b>
                </a>
                <ul class="dropdown-menu" style="line-height:20px;min-width:120px;">
                    
                        <li><a href="/study" style="line-height:20px;padding:2px 2px;">学习资源汇总</a></li>
                    
                </ul>
            </li>
            
        </ul>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/img/avatar.png">
            <h2 id="name">郑扬涛</h2>
            <h3 id="title">M.S. Student @ Beihang Univ.</h3>
            <span id="location"><i class="fa fa-map-marker"></i>Beijing, China</span>
            <a id="follow" target="_blank" href="https://www.zhihu.com/people/orzyt/activities">关注我</a>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="https://github.com/orzyt" target="_blank" title="github">
                            <i class="fa fa-github"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="https://www.linkedin.com/in/orzyt" target="_blank" title="linkedin">
                            <i class="fa fa-linkedin"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="https://weibo.com/orzyt" target="_blank" title="weibo">
                            <i class="fa fa-weibo"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/atom.xml" target="_blank" title="rss">
                            <i class="fa fa-rss"></i>
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>
        
    </div>
</aside>
            
            <section id="main"><article id="post-use-tensorflow-to-implement-logistic-regression" class="article article-type-post" itemscope="" itemprop="blogPost">
    <div class="article-inner">
        
            
	
		<img src="https://tuchuang001.com/images/2017/11/09/banner.png" class="article-banner">
	



        
        
            <header class="article-header">
                
    
    
        
            <h1 class="article-title" itemprop="name">
                使用TensorFlow实现逻辑回归
            </h1>
        
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/posts/use-tensorflow-to-implement-logistic-regression/">
            <time datetime="2017-12-02T03:31:49.000Z" itemprop="datePublished">2017-12-02</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/TensorFlow/">TensorFlow</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/TensorFlow/">TensorFlow</a>, <a class="tag-link" href="/tags/hands-on-ML/">hands-on ML</a>, <a class="tag-link" href="/tags/机器学习/">机器学习</a>, <a class="tag-link" href="/tags/逻辑回归/">逻辑回归</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
            
                
                    <h2 id="题目大意"><a href="#题目大意" class="headerlink" title="题目大意"></a>题目大意</h2><blockquote>
<p>使用TensorFlow实现小批量梯度下降的逻辑回归。<br>数据集：<a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html" target="_blank" rel="noopener"><code>moons dataset</code></a><br><em>— From《Hands-on Machine Learning with Scikit-Learn and TensorFlow》Chapter9 Exercise12</em></p>
</blockquote>
<a id="more"></a>
<hr>
<p><strong>*附加功能：</strong></p>
<blockquote>
<p>• 在<code>logistic_regression()</code>函数中定义计算图，以便复用<br>• 在训练的时候定期保存检查点，并在训练结束的时候保存最终的模型<br>• 若训练中断，则从检查点中恢复<br>• 使用命名域来定义图<br>• 增加summaries日志记录，在TensorBoard中可视化学习曲线<br>•  调参（如，学习率、批数据大小等）并观察学习曲线</p>
</blockquote>
<hr>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>首先载入数据集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_moons</span><br><span class="line">m = <span class="number">1000</span>  <span class="comment"># 样本数量</span></span><br><span class="line"><span class="comment"># 载入数据集</span></span><br><span class="line">X_moons, y_moons = make_moons(m, noise=<span class="number">0.1</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure></p>
<p>接着将数据集可视化，以便有一个直观的感受<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据可视化</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># y_moons == 1提取正样本的索引</span></span><br><span class="line">plt.plot(X_moons[y_moons == <span class="number">1</span>, <span class="number">0</span>], X_moons[y_moons == <span class="number">1</span>, <span class="number">1</span>], <span class="string">'go'</span>, label=<span class="string">'Positive'</span>)</span><br><span class="line">plt.plot(X_moons[y_moons == <span class="number">0</span>, <span class="number">0</span>], X_moons[y_moons == <span class="number">0</span>, <span class="number">1</span>], <span class="string">'r^'</span>, label=<span class="string">'Negative'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://tuchuang001.com/images/2017/12/02/moons_dataset.png" alt="moons dataset"></p>
<p>为每个样本在第0维上添加<code>bias</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加bias</span></span><br><span class="line">X_moons_with_bias = np.c_[np.ones((m, <span class="number">1</span>)), X_moons]</span><br></pre></td></tr></table></figure></p>
<p>标签形状需要从<code>(m, )</code>reshape为<code>(m, 1)</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将数据标签从 1-D reshape成 2-D</span></span><br><span class="line">y_moons_column_vector = y_moons.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>从整个数据集中以<code>8:2</code>的比例，划分出训练集和测试集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试集占整个数据集的比例</span></span><br><span class="line">test_ratio = <span class="number">0.2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试样本数量</span></span><br><span class="line">test_size = int(m * test_ratio)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集</span></span><br><span class="line">X_train = X_moons_with_bias[:-test_size]</span><br><span class="line">y_train = y_moons_column_vector[:-test_size]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分测试集</span></span><br><span class="line">X_test = X_moons_with_bias[-test_size:]</span><br><span class="line">y_test = y_moons_column_vector[-test_size:]</span><br></pre></td></tr></table></figure></p>
<p>定义一个随机划分批数据函数，方便后续训练<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_batch</span><span class="params">(X_train, y_train, batch_size)</span>:</span></span><br><span class="line">    <span class="string">''' # 随机划分批数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    :param X_train: 整个训练集样本</span></span><br><span class="line"><span class="string">    :param y_train: 整个训练集标签</span></span><br><span class="line"><span class="string">    :param batch_size: 每个batch的大小</span></span><br><span class="line"><span class="string">    :return: 样本和标签的批数据</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    rnd_indices = np.random.randint(<span class="number">0</span>, len(X_train), size=batch_size)</span><br><span class="line">    X_batch = X_train[rnd_indices]</span><br><span class="line">    y_batch = y_train[rnd_indices]</span><br><span class="line">    <span class="keyword">return</span> X_batch, y_batch</span><br></pre></td></tr></table></figure></p>
<hr>
<h2 id="构造计算图阶段"><a href="#构造计算图阶段" class="headerlink" title="构造计算图阶段"></a>构造计算图阶段</h2><p>moons dataset的特征只有2个<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特征数量</span></span><br><span class="line">n_inputs = <span class="number">2</span></span><br></pre></td></tr></table></figure></p>
<p>构造计算图<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入数据</span></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs + <span class="number">1</span>), name=<span class="string">'X'</span>)</span><br><span class="line">y = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, <span class="number">1</span>), name=<span class="string">'y'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 权值初始化</span></span><br><span class="line">theta = tf.Variable(tf.random_uniform([n_inputs + <span class="number">1</span>, <span class="number">1</span>], <span class="number">-1.0</span>, <span class="number">1.0</span>, seed=<span class="number">42</span>), name=<span class="string">'theta'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算logits</span></span><br><span class="line">logits = tf.matmul(X, theta, name=<span class="string">'logits'</span>)</span><br></pre></td></tr></table></figure></p>
<p>sigmod函数的计算方式<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方式一（根据定义）</span></span><br><span class="line">y_proba = <span class="number">1</span> / (<span class="number">1</span> + tf.exp(-logits))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式二（内建函数）</span></span><br><span class="line">y_proba = tf.sigmoid(logits)</span><br></pre></td></tr></table></figure></p>
<p>计算逻辑回归的损失函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方式一（根据定义）</span></span><br><span class="line">epsilon = <span class="number">1e-7</span> <span class="comment"># 避免运算溢出</span></span><br><span class="line">loss = -tf.reduce_mean(y * tf.log(y_proba + epsilon) + (<span class="number">1</span> - y) * tf.log(<span class="number">1</span> - y_proba + epsilon), name = <span class="string">'loss'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式二（内建函数）</span></span><br><span class="line">loss = tf.losses.log_loss(y, y_proba, epsilon=epsilon)</span><br></pre></td></tr></table></figure></p>
<p>定义学习率、梯度下降优化器及变量初始化节点<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">0.01</span> <span class="comment"># 学习率</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降优化器</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)</span><br><span class="line"><span class="comment"># 训练节点</span></span><br><span class="line">training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 变量初始化节点</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure></p>
<p>训练相关的参数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练的epoch次数（即遍历epoch次整个数据集）</span></span><br><span class="line">n_epochs = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 每次批训练的样本数量</span></span><br><span class="line">batch_size = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 完成一次epoch所需要的批训练次数</span></span><br><span class="line">n_batches = int(np.ceil(m / batch_size))</span><br></pre></td></tr></table></figure></p>
<hr>
<h2 id="运行计算图阶段"><a href="#运行计算图阶段" class="headerlink" title="运行计算图阶段"></a>运行计算图阶段</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> batch_index <span class="keyword">in</span> range(n_batches):</span><br><span class="line">            <span class="comment"># 获取批数据</span></span><br><span class="line">            X_batch, y_batch = random_batch(X_train, y_train, batch_size)</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        loss_val = loss.eval(feed_dict=&#123;X: X_test, y: y_test&#125;)</span><br><span class="line">        <span class="comment"># 每训练100个epoch打印当前的loss值</span></span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Epoch:'</span>, epoch, <span class="string">'\tLoss:'</span>, loss_val)</span><br><span class="line">    <span class="comment"># 在测试集上预测</span></span><br><span class="line">    y_proba_val = y_proba.eval(feed_dict=&#123;X: X_test, y: y_test&#125;)</span><br></pre></td></tr></table></figure>
<p>将概率大等于0.5的样本预测为正类<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = (y_proba_val &gt;= <span class="number">0.5</span>)</span><br></pre></td></tr></table></figure></p>
<hr>
<h2 id="模型评价"><a href="#模型评价" class="headerlink" title="模型评价"></a>模型评价</h2><p>使用准确率（precision）和召回率（recall）来评价模型<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score, recall_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准确率</span></span><br><span class="line">p_score = precision_score(y_test, y_pred)</span><br><span class="line"><span class="comment"># 召回率</span></span><br><span class="line">r_score = recall_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Precision score:'</span>, p_score)</span><br><span class="line">print(<span class="string">'Recall score:'</span>, r_score)</span><br></pre></td></tr></table></figure></p>
<hr>
<h2 id="可视化预测结果"><a href="#可视化预测结果" class="headerlink" title="可视化预测结果"></a>可视化预测结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y_pred_idx = y_pred.reshape(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(X_test[y_pred_idx, <span class="number">1</span>], X_test[y_pred_idx, <span class="number">2</span>], <span class="string">'go'</span>, label=<span class="string">'Positive'</span>)</span><br><span class="line">plt.plot(X_test[~y_pred_idx, <span class="number">1</span>], X_test[~y_pred_idx, <span class="number">2</span>], <span class="string">'r^'</span>, label=<span class="string">'Negative'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tuchuang001.com/images/2017/12/02/result1.png" alt="预测结果可视化"></p>
<hr>
<h2 id="实现附加功能"><a href="#实现附加功能" class="headerlink" title="实现附加功能"></a>实现附加功能</h2><p>由于逻辑回归是一个线性分类器（从上面可视化的预测结果也可看出），效果不是特别好。<br>因此，我们使用多项式回归，即额外增加4个特征($x_{1}^2$、$x_{2}^2$、$x_{1}^3$、$x_{2}^3$)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 增加4个特征</span></span><br><span class="line">X_train_enhanced = np.c_[X_train, X_train[:, <span class="number">1</span>] ** <span class="number">2</span>,</span><br><span class="line">                         X_train[:, <span class="number">2</span>] ** <span class="number">2</span>,</span><br><span class="line">                         X_train[:, <span class="number">1</span>] ** <span class="number">3</span>,</span><br><span class="line">                         X_train[:, <span class="number">2</span>] ** <span class="number">3</span>,]</span><br><span class="line">X_test_enhanced = np.c_[X_test,</span><br><span class="line">                        X_test[:, <span class="number">1</span>] ** <span class="number">2</span>,</span><br><span class="line">                        X_test[:, <span class="number">2</span>] ** <span class="number">2</span>,</span><br><span class="line">                        X_test[:, <span class="number">1</span>] ** <span class="number">3</span>,</span><br><span class="line">                        X_test[:, <span class="number">2</span>] ** <span class="number">3</span>,]</span><br></pre></td></tr></table></figure>
<p>将逻辑回归封装成一个函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logistic_regression</span><span class="params">(X, y, initializer=None, seed=<span class="number">42</span>, learning_rate=<span class="number">0.01</span>)</span>:</span></span><br><span class="line">    <span class="string">''' 逻辑回归</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    :param X: 样本</span></span><br><span class="line"><span class="string">    :param y: 标签</span></span><br><span class="line"><span class="string">    :param initializer: 权值初始化器</span></span><br><span class="line"><span class="string">    :param seed: 随机数种子</span></span><br><span class="line"><span class="string">    :param learning_rate: 学习率</span></span><br><span class="line"><span class="string">    :return: sigmod概率, 损失函数, 训练节点, loss日志记录, 保存器</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    n_inputs_with_bias = int(X.get_shape()[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'logistic_regression'</span>): <span class="comment"># 使用命名域</span></span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'model'</span>):</span><br><span class="line">            <span class="keyword">if</span> initializer <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                initializer = tf.random_uniform([n_inputs_with_bias, <span class="number">1</span>], <span class="number">-1.0</span>, <span class="number">1.0</span>, seed=seed)</span><br><span class="line">            theta = tf.Variable(initializer, name=<span class="string">'theta'</span>)</span><br><span class="line">            logits = tf.matmul(X, theta)</span><br><span class="line">            y_proba = tf.sigmoid(logits)</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'train'</span>):</span><br><span class="line">            loss = tf.losses.log_loss(y, y_proba, scope=<span class="string">'loss'</span>)</span><br><span class="line">            optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)</span><br><span class="line">            training_op = optimizer.minimize(loss)</span><br><span class="line">            loss_summary = tf.summary.scalar(<span class="string">'log_loss'</span>, loss)</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'init'</span>):</span><br><span class="line">            init = tf.global_variables_initializer()</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'save'</span>):</span><br><span class="line">            saver = tf.train.Saver()</span><br><span class="line">    <span class="keyword">return</span> y_proba, loss, training_op, loss_summary, init, saver</span><br></pre></td></tr></table></figure></p>
<p>构造日志文件目录<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log_dir</span><span class="params">(prefix=<span class="string">''</span>)</span>:</span></span><br><span class="line">    now = datetime.utcnow().strftime(<span class="string">'%Y%m%d%H%M%S'</span>)</span><br><span class="line">    root_logdir = <span class="string">'tf_logs'</span></span><br><span class="line">    <span class="keyword">if</span> prefix:</span><br><span class="line">        prefix += <span class="string">'-'</span></span><br><span class="line">    name = prefix + <span class="string">'run-'</span> + now</span><br><span class="line">    <span class="keyword">return</span> <span class="string">'&#123;&#125;/&#123;&#125;/'</span>.format(root_logdir, name)</span><br></pre></td></tr></table></figure></p>
<p>构造计算图<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特征数量，注意额外增加了4个特征</span></span><br><span class="line">n_inputs = <span class="number">2</span> + <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 日志文件目录</span></span><br><span class="line">logdir = log_dir(<span class="string">'logreg'</span>)</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs + <span class="number">1</span>), name=<span class="string">'X'</span>)</span><br><span class="line">y = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, <span class="number">1</span>), name=<span class="string">'y'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 封装好logistic_regression，直接调用</span></span><br><span class="line">y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存计算图结构</span></span><br><span class="line">file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())</span><br></pre></td></tr></table></figure></p>
<p>运行计算图<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">n_epochs = <span class="number">10001</span></span><br><span class="line">batch_size = <span class="number">50</span></span><br><span class="line">n_batches = int(np.ceil(m / batch_size))</span><br><span class="line"></span><br><span class="line">checkpoint_path = <span class="string">'./tmp/my_logreg_model.ckpt'</span></span><br><span class="line">checkpoint_epoch_path = checkpoint_path + <span class="string">'.epoch'</span></span><br><span class="line">final_model_path = <span class="string">'./my_logreg_model'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 判断checkpoint_epoch_path文件是否存在</span></span><br><span class="line">    <span class="keyword">if</span> os.path.isfile(checkpoint_epoch_path):</span><br><span class="line">        <span class="keyword">with</span> open(checkpoint_epoch_path, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="comment"># 文件记录了最后一次保存的epoch编号</span></span><br><span class="line">            start_epoch = int(f.read())</span><br><span class="line">        print(<span class="string">'Training was interrupted. Continuing at epoch'</span>, start_epoch)</span><br><span class="line">        <span class="comment"># 恢复会话</span></span><br><span class="line">        saver.restore(sess, checkpoint_path)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 重新开始</span></span><br><span class="line">        start_epoch = <span class="number">0</span></span><br><span class="line">        sess.run(init)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(start_epoch, n_epochs):</span><br><span class="line">        <span class="keyword">for</span> batch_index <span class="keyword">in</span> range(n_batches):</span><br><span class="line">            X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 计算每个epoch的loss值及其日志记录</span></span><br><span class="line">        loss_val, summary_str = sess.run([loss, loss_summary], feed_dict=&#123;X: X_test_enhanced, y: y_test&#125;)</span><br><span class="line">        <span class="comment"># 追加loss日志记录,注意当前epoch的编号也要记录</span></span><br><span class="line">        file_writer.add_summary(summary_str, epoch)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 每500个epoch保存checkpoint</span></span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Epoch:'</span>, epoch, <span class="string">'\tLoss:'</span>, loss_val)</span><br><span class="line">            saver.save(sess, checkpoint_path)</span><br><span class="line">            <span class="comment"># 每次覆盖写入新的epoch编号</span></span><br><span class="line">            <span class="keyword">with</span> open(checkpoint_epoch_path, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(<span class="string">b'%d'</span> % (epoch + <span class="number">1</span>))</span><br><span class="line">                </span><br><span class="line">    <span class="comment"># 保存最终模型            </span></span><br><span class="line">    saver.save(sess, final_model_path)</span><br><span class="line">    <span class="comment"># 在测试集上进行预测</span></span><br><span class="line">    y_proba_val = y_proba.eval(feed_dict=&#123;X: X_test_enhanced, y: y_test&#125;)</span><br><span class="line">    <span class="comment"># 若训练未中断,则删除checkpoint_epoch_path文件</span></span><br><span class="line">    os.remove(checkpoint_epoch_path)</span><br></pre></td></tr></table></figure></p>
<p>预测结果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = (y_proba_val &gt;= <span class="number">0.5</span>)</span><br></pre></td></tr></table></figure></p>
<p>输出准确率和召回率<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Precision score:'</span>, precision_score(y_test, y_pred))</span><br><span class="line">print(<span class="string">'Recall score:'</span>, recall_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></p>
<p>可视化预测结果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y_pred_idx = y_pred.reshape(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(X_test[y_pred_idx, <span class="number">1</span>], X_test[y_pred_idx, <span class="number">2</span>], <span class="string">'go'</span>, label=<span class="string">'Positive'</span>)</span><br><span class="line">plt.plot(X_test[~y_pred_idx, <span class="number">1</span>], X_test[~y_pred_idx, <span class="number">2</span>], <span class="string">'r^'</span>, label=<span class="string">'Negative'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://tuchuang001.com/images/2017/12/02/result2.png" alt="可视化预测结果"></p>
<p>可以看出，增加额外4个特征，能够显著提高预测结果</p>
<hr>
<p>开始对<code>learning rate</code>和<code>batch size</code>进行玄学调参…</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> reciprocal</span><br><span class="line"></span><br><span class="line">n_search_iterations = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> search_iteration <span class="keyword">in</span> range(n_search_iterations):</span><br><span class="line">    batch_size = np.random.randint(<span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">    <span class="comment"># reciprocal为倒数分布</span></span><br><span class="line">    <span class="comment"># 详见https://en.wikipedia.org/wiki/Reciprocal_distribution</span></span><br><span class="line">    <span class="comment"># 一般来说，如果对超参数的最优量级没把握的话，可以使用该分布进行调参</span></span><br><span class="line">    learning_rate = reciprocal.rvs(<span class="number">0.0001</span>, <span class="number">0.1</span>, random_state=search_iteration)</span><br><span class="line">    </span><br><span class="line">    n_inputs = <span class="number">2</span> + <span class="number">4</span></span><br><span class="line">    logdir = log_dir(<span class="string">'logdir'</span>)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">'Iteration'</span>, search_iteration)</span><br><span class="line">    print(<span class="string">'  logdir:'</span>, logdir)</span><br><span class="line">    print(<span class="string">'  batch size:'</span>, batch_size)</span><br><span class="line">    print(<span class="string">'  learning rate:'</span>, learning_rate)</span><br><span class="line">    print(<span class="string">'  training: '</span>, end=<span class="string">''</span>)</span><br><span class="line">    </span><br><span class="line">    X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs + <span class="number">1</span>), name=<span class="string">'X'</span>)</span><br><span class="line">    y = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, <span class="number">1</span>), name=<span class="string">'y'</span>)</span><br><span class="line">    </span><br><span class="line">    y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(X, y, learning_rate=learning_rate)</span><br><span class="line">    </span><br><span class="line">    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())</span><br><span class="line">    </span><br><span class="line">    n_epochs = <span class="number">10001</span></span><br><span class="line">    n_batches = int(np.ceil(m / batch_size))</span><br><span class="line">    </span><br><span class="line">    final_model_path = <span class="string">'./model/my_logreg_model_%d'</span> % search_iteration</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(init)</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">            <span class="keyword">for</span> batch_index <span class="keyword">in</span> range(n_batches):</span><br><span class="line">                X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)</span><br><span class="line">                sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">            loss_val, summary_str = sess.run([loss, loss_summary], feed_dict=&#123;X: X_test_enhanced, y: y_test&#125;)    </span><br><span class="line">            file_writer.add_summary(summary_str, epoch)</span><br><span class="line">            <span class="keyword">if</span> epoch % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">'.'</span>, end=<span class="string">''</span>)</span><br><span class="line">        print()</span><br><span class="line">        </span><br><span class="line">        saver.save(sess, final_model_path)</span><br><span class="line">        </span><br><span class="line">        y_proba_val = y_proba.eval(feed_dict=&#123;X: X_test_enhanced, y: y_test&#125;)</span><br><span class="line">        y_pred = (y_proba_val &gt;= <span class="number">0.5</span>)</span><br><span class="line">        </span><br><span class="line">        print(<span class="string">'  Precision:'</span>, precision_score(y_test, y_pred))</span><br><span class="line">        print(<span class="string">'  Recall:'</span>, recall_score(y_test, y_pred))</span><br></pre></td></tr></table></figure>
<p>打印训练信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">Iteration 0</span><br><span class="line">  logdir: tf_logs/logdir-run-20171202101244/</span><br><span class="line">  batch size: 54</span><br><span class="line">  learning rate: 0.00443037524522</span><br><span class="line">  training: .....................</span><br><span class="line">  Precision: 0.979797979798</span><br><span class="line">  Recall: 0.979797979798</span><br><span class="line">Iteration 1</span><br><span class="line">  logdir: tf_logs/logdir-run-20171202101623/</span><br><span class="line">  batch size: 22</span><br><span class="line">  learning rate: 0.00178264971514</span><br><span class="line">  training: .....................</span><br><span class="line">  Precision: 0.979797979798</span><br><span class="line">  Recall: 0.979797979798</span><br><span class="line">Iteration 2</span><br><span class="line">  logdir: tf_logs/logdir-run-20171202102501/</span><br><span class="line">  batch size: 74</span><br><span class="line">  learning rate: 0.00203228544324</span><br><span class="line">  training: .....................</span><br><span class="line">  Precision: 0.969696969697</span><br><span class="line">  Recall: 0.969696969697</span><br><span class="line">Iteration 3</span><br><span class="line">  logdir: tf_logs/logdir-run-20171202102742/</span><br><span class="line">  batch size: 58</span><br><span class="line">  learning rate: 0.00449152382514</span><br><span class="line">  training: .....................</span><br><span class="line">  Precision: 0.979797979798</span><br><span class="line">  Recall: 0.979797979798</span><br><span class="line">Iteration 4</span><br><span class="line">  logdir: tf_logs/logdir-run-20171202103106/</span><br><span class="line">  batch size: 61</span><br><span class="line">  learning rate: 0.0796323472178</span><br><span class="line">  training: .....................</span><br><span class="line">  Precision: 0.980198019802</span><br><span class="line">  Recall: 1.0</span><br><span class="line">Iteration 5</span><br><span class="line">  logdir: tf_logs/logdir-run-20171202103417/</span><br><span class="line">  batch size: 92</span><br><span class="line">  learning rate: 0.000463425058329</span><br><span class="line">  training: .....................</span><br><span class="line">  Precision: 0.912621359223</span><br><span class="line">  Recall: 0.949494949495</span><br><span class="line">Iteration 6</span><br><span class="line">  logdir: tf_logs/logdir-run-20171202103630/</span><br><span class="line">  batch size: 74</span><br><span class="line">  learning rate: 0.0477068184194</span><br><span class="line">  training: .....................</span><br><span class="line">  Precision: 0.98</span><br><span class="line">  Recall: 0.989898989899</span><br><span class="line">Iteration 7</span><br><span class="line">  logdir: tf_logs/logdir-run-20171202103916/</span><br><span class="line">  batch size: 58</span><br><span class="line">  learning rate: 0.000169404470952</span><br><span class="line">  training: .....................</span><br><span class="line">  Precision: 0.9</span><br><span class="line">  Recall: 0.909090909091</span><br><span class="line">Iteration 8</span><br><span class="line">  logdir: tf_logs/logdir-run-20171202104242/</span><br><span class="line">  batch size: 61</span><br><span class="line">  learning rate: 0.0417146119941</span><br><span class="line">  training: .....................</span><br><span class="line">  Precision: 0.980198019802</span><br><span class="line">  Recall: 1.0</span><br><span class="line">Iteration 9</span><br><span class="line">  logdir: tf_logs/logdir-run-20171202104602/</span><br><span class="line">  batch size: 92</span><br><span class="line">  learning rate: 0.000107429229684</span><br><span class="line">  training: .....................</span><br><span class="line">  Precision: 0.882352941176</span><br><span class="line">  Recall: 0.757575757576</span><br></pre></td></tr></table></figure></p>
<p>  让我们打开<code>TensorBoard</code>观察10次训练的学习曲线</p>
<p>  <img src="https://tuchuang001.com/images/2017/12/02/result3.png" alt="10次训练的学习曲线"></p>
<p>  可以看出，第4次（从0开始）的<code>loss</code>值最小<br>  最终，找到的超参数为</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">超参数</th>
<th style="text-align:center">取值</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">learning rate</td>
<td style="text-align:center">0.0796323472178</td>
</tr>
<tr>
<td style="text-align:center">batch size</td>
<td style="text-align:center">61</td>
</tr>
</tbody>
</table>
</div>

                
            
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://orzyt.cn/posts/use-tensorflow-to-implement-logistic-regression/" data-id="cjtwf873y00pp8jsih0uhsggm" class="article-share-link"><i class="fa fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="https://orzyt.cn/posts/use-tensorflow-to-implement-logistic-regression/#comments" class="article-comment-link">评论</a>
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/posts/generative-adversarial-nets/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    生成对抗网络(Generative Adversarial Nets)
                
            </div>
        </a>
    
    
        <a href="/posts/hands-on-ml-up-and-running-tensorflow/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">Hands-on Machine learning 之 TensorFLow入门</div>
        </a>
    
</nav>


    
</article>


    
    
        <section id="comments">
<div id="gitalkContainer"></div>
</section>
    

</section>
            
                
<aside id="sidebar" style="position: sticky; top:-0.75rem;">
   
        
<div class="toc-article" id="toc">
    <h3 class="widget-title" style="font-size:14px;"><i class="fa fa-list-alt" style="color: #888;font-size: 14px;margin-right: 10px;"></i>文章目录</h3>
    <div class="widget-toc">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#题目大意"><span class="toc-number">1.</span> <span class="toc-text">题目大意</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据预处理"><span class="toc-number">2.</span> <span class="toc-text">数据预处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#构造计算图阶段"><span class="toc-number">3.</span> <span class="toc-text">构造计算图阶段</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#运行计算图阶段"><span class="toc-number">4.</span> <span class="toc-text">运行计算图阶段</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#模型评价"><span class="toc-number">5.</span> <span class="toc-text">模型评价</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#可视化预测结果"><span class="toc-number">6.</span> <span class="toc-text">可视化预测结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实现附加功能"><span class="toc-number">7.</span> <span class="toc-text">实现附加功能</span></a></li></ol>
    </div>
</div>

    
        

    
        


    
</aside>
<div id="toTop" class="fa fa-angle-up"></div>

            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2019 orzyt<br>
            Powered by <a rel="”nofollow”" href="http://hexo.io/" target="_blank">Hexo</a> | Hosted by <a rel="”nofollow”" href="https://pages.coding.me">Coding Pages</a>
        </div>
    </div>
</footer>
        

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script>
    var gitalk = new Gitalk({
        id: location.pathname,
        clientID: '3628f46ff8965c297258', 
        clientSecret: 'da2ef51d9fe687db577e834867d253a697f19a9f',
        repo: 'comments',
        owner: 'orzyt',
        admin: ['orzyt'],
        distractionFreeMode: false,
        perPage: 20,
        createIssueManually: false,
        language: 'zh-CN', 
    })
    gitalk.render('gitalkContainer')
</script>







<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ 
        tex2jax: { 
            inlineMath: [['$','$'], ['\\(','\\)']] }, 
            displayMath: [["$$","$$"]],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a'],
            showProcessingMessages: false,
            messageStyle: "none",
        }
    );
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
    <!-- page.__post !== true --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>


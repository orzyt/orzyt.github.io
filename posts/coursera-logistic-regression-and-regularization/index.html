<!DOCTYPE html>
<html lang="zh">
<head><meta name="generator" content="Hexo 3.8.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    
    <title>Coursera Machine Learning 逻辑回归和正则化 - 扬涛的博客</title>
    <meta itemprop="name" content="Coursera Machine Learning 逻辑回归和正则化 - 扬涛的博客">
    
    <meta name="keywords" content="扬涛的博客, 郑扬涛, orzyt, leetcode">
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    
    <link rel="alternate" href="/atom.xml" title="扬涛的博客" type="application/atom+xml">
    
    
    <link rel="icon" href="/favicon.ico">
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">
    <link rel="stylesheet" href="/libs/bootstrap/css/bootstrap.min.css">
    <!--<link rel="stylesheet" href="/libs/headroom/animate.css">-->
    

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    <script src="/libs/bootstrap/js/bootstrap.min.js"></script>
    <!--<script src="/libs/headroom/headroom.min.js"></script>-->
    <!--<script src="/libs/headroom/jQuery.headroom.min.js"></script>-->
    <script src="/libs/jquery/sort.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
    
    
    
        <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?63f226f2212285cc30d6ffa0636da07a";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    


</head>
</html>
<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">扬涛的博客</span>
            </a>
            <nav id="main-nav">
                <div>
                    <ul class="nav navbar-nav">
                    
                        <a class="main-nav-link" href="/.">主页</a>
                    
                        <a class="main-nav-link" href="/archives">归档</a>
                    
                        <a class="main-nav-link" href="/books">阅读</a>
                    
                        <a class="main-nav-link" href="/about">关于</a>
                    
                    
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">
                            更多 
                            <b class="caret"></b>
                        </a>
                        <ul class="dropdown-menu">
                            
                                <li><a href="/study">学习资源汇总</a></li>
                            
                        </ul>
                    </li>
                    
                    </ul>
                </div>
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/img/avatar.png">
                            <i class="fa fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <ul class="menu outer">
            
                <a class="main-nav-link" href="/.">主页</a>
            
                <a class="main-nav-link" href="/archives">归档</a>
            
                <a class="main-nav-link" href="/books">阅读</a>
            
                <a class="main-nav-link" href="/about">关于</a>
            
                           
            <li class="dropdown">
                <a href="#" class="dropdown-toggle" data-toggle="dropdown">
                    更多 
                    <b class="caret"></b>
                </a>
                <ul class="dropdown-menu" style="line-height:20px;min-width:120px;">
                    
                        <li><a href="/study" style="line-height:20px;padding:2px 2px;">学习资源汇总</a></li>
                    
                </ul>
            </li>
            
        </ul>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/img/avatar.png">
            <h2 id="name">郑扬涛</h2>
            <h3 id="title">M.S. Student @ Beihang Univ.</h3>
            <span id="location"><i class="fa fa-map-marker"></i>Beijing, China</span>
            <a id="follow" target="_blank" href="https://www.zhihu.com/people/orzyt/activities">关注我</a>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="https://github.com/orzyt" target="_blank" title="github">
                            <i class="fa fa-github"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="https://www.linkedin.com/in/orzyt" target="_blank" title="linkedin">
                            <i class="fa fa-linkedin"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="https://weibo.com/orzyt" target="_blank" title="weibo">
                            <i class="fa fa-weibo"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/atom.xml" target="_blank" title="rss">
                            <i class="fa fa-rss"></i>
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>
        
    </div>
</aside>
            
            <section id="main"><article id="post-coursera-logistic-regression-and-regularization" class="article article-type-post" itemscope="" itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
    
        
            <h1 class="article-title" itemprop="name">
                Coursera Machine Learning 逻辑回归和正则化
            </h1>
        
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/posts/coursera-logistic-regression-and-regularization/">
            <time datetime="2017-02-03T16:00:00.000Z" itemprop="datePublished">2017-02-04</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/机器学习/">机器学习</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
            
                
                    <h2 id="二元分类"><a href="#二元分类" class="headerlink" title="二元分类"></a>二元分类</h2><p>对于二元分类来说，其输出值 $y$ 不再是一个连续的值，而是属于 $\lbrace 0,1 \rbrace$，一般0代表<code>negative class</code>，而1代表<code>positive class</code>。想要实现二元分类，一种方法是在线性回归的基础上进行修改，比如说输出值$y$超过了某一阈值，则认为它属于1，否则属于0，但是这个效果通常来说不是很好。</p>
<a id="more"></a>
<h2 id="假设函数的表示"><a href="#假设函数的表示" class="headerlink" title="假设函数的表示"></a>假设函数的表示</h2><p>首先，分类问题中的$h_\theta (x)$函数要满足$0 \leq h_\theta (x) \leq 1$，为此引入一个新的函数——<code>Sigmoid Function</code>。sigmoid函数定义为：$g(z) = \dfrac{1}{1 + e^{-z}}$，它可以将任意的实数映射到区间$(0, 1)$ 。函数的大致图像如下：</p>
<p><img src="https://tuchuang001.com/images/2017/02/04/lecture6-1.png" alt="sigmoid函数" width="70%" height="70%"></p>
<p>在分类问题中，$h_\theta (x) =  g ( \theta^T x )$，也就是在sigmoid函数作用下，将原本线性回归的输出值映射到$(0, 1)$区间。同时$h_\theta (x)$的含义也有了变化，代表着在输入为$x$的情况下 ，其类别为<code>1</code>的概率大小。形式化的表示就是：$h_\theta(x) = P(y = 1 | x; \theta)$</p>
<h2 id="决策边界"><a href="#决策边界" class="headerlink" title="决策边界"></a>决策边界</h2><p>在将$h_\theta (x)$ 映射到$ (0, 1) $区间之后，我们可以认为当$h_\theta(x) \geq 0.5 $时$y = 1$，$h_\theta(x) &lt; 0.5$时$y = 0$。观察sigmoid函数的图像不难发现，$z \geq 0$ 时 $g(z) \geq 0.5 $，因此 $y = 1$ 的充要条件就是 $\theta^T x &gt;= 0$ 。而所谓的决策边界(decision boundary)就是 $ \theta^T x = 0$ 所构成的曲线。</p>
<p><img src="https://tuchuang001.com/images/2017/02/04/lecture6-2.png" alt="decision boundary" width="80%" height="80%"></p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>逻辑回归的损失函数如下：</p>
<script type="math/tex; mode=display">\begin{align*}& J(\theta) = \dfrac{1}{m} \sum_{i=1}^m \mathrm{Cost}(h_\theta(x^{(i)}),y^{(i)}) \newline & 其中\newline & \mathrm{Cost}(h_\theta(x),y) = -\log(h_\theta(x)) \; & \text{if y = 1} \newline & \mathrm{Cost}(h_\theta(x),y) = -\log(1-h_\theta(x)) \; & \text{if y = 0}\end{align*}</script><p>还是先来看下函数图像，有一个直观的感受</p>
<center>
<img src="https://tuchuang001.com/images/2017/02/04/lecture6-3.png" alt="" width="30%" height="30%">
<img src="https://tuchuang001.com/images/2017/02/04/lecture6-4.png" alt="" width="30%" height="30%">
</center>

<p>上述的 Cost 函数要分类讨论，计算的时候比较麻烦。其实可以化简成一个式子来表示两种情况，就是  $\mathrm{Cost}(h_\theta(x),y) = - y \; \log(h_\theta(x)) - (1 - y) \log(1 - h_\theta(x))$  ，不难验证两者是等价的。</p>
<h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>$J(\theta) = - \frac{1}{m} \displaystyle \sum_{i=1}^m [y^{(i)}\log (h_\theta (x^{(i)})) + (1 - y^{(i)})\log (1 - h_\theta(x^{(i)}))]$</p>
<p>梯度下降算法（跟线性回归时的一样）：</p>
<script type="math/tex; mode=display">\begin{align*}& Repeat \; \lbrace \newline & \; \theta_j := \theta_j - \alpha \dfrac{\partial}{\partial \theta_j}J(\theta) \newline & \rbrace\end{align*}</script><p>其中，$\dfrac{\partial}{\partial \theta_j}J(\theta)  = \frac{1}{m}\sum_{i=1}^m \left [ h_\theta(x^{(i)}) - y^{(i)} \right ] x^{(i)}_j$</p>
<h2 id="高级优化"><a href="#高级优化" class="headerlink" title="高级优化"></a>高级优化</h2><p>虽然采用梯度下降算法也能求得结果，但是还存在一些更好的优化算法。不过一般来说都会比较复杂，没必要自己亲自实现。Matlab或Octave中有提供一个<code>fminunc</code>函数可以用来找到一个无约束多变量函数的最小值 (Find a minimum of an unconstrained multivariable function) 。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">示例代码：</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[jVal, gradient]</span> = <span class="title">costFunction</span><span class="params">(theta)</span></span></span><br><span class="line">  jVal = [...code to compute J(theta)...];</span><br><span class="line">  gradient = [...code to compute derivative of J(theta)...];</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">options = optimset(<span class="string">'GradObj'</span>, <span class="string">'on'</span>, <span class="string">'MaxIter'</span>, <span class="number">100</span>);</span><br><span class="line">initialTheta = <span class="built_in">zeros</span>(<span class="number">2</span>,<span class="number">1</span>);</span><br><span class="line">[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);</span><br></pre></td></tr></table></figure>
<p>具体用法参阅：<a href="https://cn.mathworks.com/help/optim/ug/fminunc-unconstrained-minimization.html" target="_blank" rel="noopener">fminunc Unconstrained Minimization</a></p>
<h2 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h2><p>在多分类问题中，结果不再仅仅只有0、1两类，而是可能有多种分类结果。那么此时该如何处理呢？</p>
<p>其实很简单，One-vs-all！将多分类问题转化成二元分类问题。</p>
<p>比如$y \in \lbrace0, 1 … n\rbrace$ ，那么我们可以训练 $n+1$ 个二元分类器 $h_\theta ^{(0)}(x),  h_\theta ^{(1)}(x), …, h_\theta ^{(n)}(x)$ 。在第 $i$ 个二元分类器中，它只要计算当前输入为第 $i$ 个分类的概率。那么样本的类别就是等于这 $n+1$个结果中概率最大的那个类别，即 $ \mathrm{类别} = \max_i( h_\theta ^{(i)}(x) ) $ 。</p>
<p><img src="https://tuchuang001.com/images/2017/02/04/lecture6-5.png" alt="one vs all" width="80%" height="80%"></p>
<h2 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h2><p><strong>欠拟合</strong>(underfitting)：模型复杂度过低，不能很好的拟合所有的数据，训练误差大。</p>
<p><strong>过拟合</strong>(Overfitting)：模型复杂度过高，训练数据过少，训练误差虽小，但测试误差大。</p>
<p>欠拟合对应<strong>高偏差(bias)</strong>，过拟合对应<strong>高方差(variance)</strong>。</p>
<p><img src="https://tuchuang001.com/images/2017/02/04/lecture7-1.png" alt="one vs all" width="80%" height="80%"></p>
<h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>通过在损失函数中加入正则化项(regularizer)来避免过拟合问题。</p>
<script type="math/tex; mode=display">min_\theta\ \dfrac{1}{2m}\ \left[ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 + \lambda\ \sum_{j=1}^n \theta_j^2 \right]</script><p>其中，$\lambda$ 称作正则化参数，用来控制<strong>拟合训练数据</strong>和<strong>保持参数值较小</strong>这两个目标之间的关系。</p>
<ul>
<li><p>对线性回归进行正则化</p>
<p><strong>梯度下降：</strong></p>
<script type="math/tex; mode=display">\begin{align*} & \text{Repeat}\ \lbrace \newline & \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \newline & \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] &\ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2...n\rbrace\newline & \rbrace\end{align*}</script><p><strong>正规方程(Normal equation)：</strong></p>
<script type="math/tex; mode=display">\begin{align*}& \theta = \left( X^TX + \lambda \cdot L \right)^{-1} X^Ty \newline& \text{其中}\ \ L = \begin{bmatrix} 0 & & & & \newline & 1 & & & \newline & & 1 & & \newline & & & \ddots & \newline & & & & 1 \newline\end{bmatrix}\end{align*}</script></li>
</ul>
<ul>
<li><p>对逻辑回归进行正则化</p>
<script type="math/tex; mode=display">J(\theta) = - \frac{1}{m} \sum_{i=1}^m \large[ y^{(i)}\ \log (h_\theta (x^{(i)})) + (1 - y^{(i)})\ \log (1 - h_\theta(x^{(i)}))\large] + \frac{\lambda}{2m}\sum_{j=1}^n \theta_j^2</script><p><strong>梯度下降：</strong></p>
<script type="math/tex; mode=display">\begin{align*}& \text{Repeat}\ \lbrace \newline& \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \newline& \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] &\ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2...n\rbrace\newline& \rbrace\end{align*}</script></li>
</ul>
<p>需要注意的是，一般都不对 $\theta_0$ 进行正则化（$\theta_0$ 恒为1），因此在上面的公式中下标 $j$ 都从1开始。</p>

                
            
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://orzyt.cn/posts/coursera-logistic-regression-and-regularization/" data-id="cjtr5os2l00132isiq335wcu0" class="article-share-link"><i class="fa fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="https://orzyt.cn/posts/coursera-logistic-regression-and-regularization/#comments" class="article-comment-link">评论</a>
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/posts/coursera-neural-networks-model/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    Coursera Machine Learning 神经网络模型
                
            </div>
        </a>
    
    
        <a href="/posts/leetcode268-missing-number/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">LeetCode268 Missing Number</div>
        </a>
    
</nav>


    
</article>


    
    
        <section id="comments">
    <div id="gitalkContainer"></div>
</section>
    

</section>
            
                
<aside id="sidebar">
   
        
<div class="toc-article" id="toc">
    <h3 class="widget-title" style="font-size:14px;"><i class="fa fa-list-alt" style="color: #888;font-size: 14px;margin-right: 10px;"></i>文章目录</h3>
    <div class="widget-toc">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#二元分类"><span class="toc-number">1.</span> <span class="toc-text">二元分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#假设函数的表示"><span class="toc-number">2.</span> <span class="toc-text">假设函数的表示</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#决策边界"><span class="toc-number">3.</span> <span class="toc-text">决策边界</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#损失函数"><span class="toc-number">4.</span> <span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#梯度下降"><span class="toc-number">5.</span> <span class="toc-text">梯度下降</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#高级优化"><span class="toc-number">6.</span> <span class="toc-text">高级优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多分类问题"><span class="toc-number">7.</span> <span class="toc-text">多分类问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#过拟合"><span class="toc-number">8.</span> <span class="toc-text">过拟合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#正则化"><span class="toc-number">9.</span> <span class="toc-text">正则化</span></a></li></ol>
    </div>
</div>

    
        

    
        


    
</aside>
<div id="toTop" class="fa fa-angle-up"></div>

            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2019 orzyt<br>
            Powered by <a rel="”nofollow”" href="http://hexo.io/" target="_blank">Hexo</a> | Hosted by <a rel="”nofollow”" href="https://pages.coding.me">Coding Pages</a>
        </div>
    </div>
</footer>
        
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
    <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
	<script>
        var gitalk = new Gitalk({
            id: location.pathname,
            clientID: '3628f46ff8965c297258', 
            clientSecret: 'da2ef51d9fe687db577e834867d253a697f19a9f',
            repo: 'comments',
            owner: 'orzyt',
            admin: ['orzyt'],
            distractionFreeMode: false,
            perPage: 20,
            createIssueManually: false,
            language: 'zh-CN', 
        })
        gitalk.render('gitalkContainer')
	</script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
    <!-- page.__post !== true --><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>

